{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url='https://query.data.world/s/wh6j7rxy2hvrn4ml75ci62apk5hgae'\n",
    "#df = pd.read_csv(url,error_bad_lines = False)\n",
    "#url= 'https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+'\n",
    "#data = pd.read_csv(url,error_bad_lines = False)\n",
    "#data = pd.read_csv('https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+') \n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv')\n",
    "#data = pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\Hamoye\\\\Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>-0.031810</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>0.045263</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1     9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2     8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3     0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4     3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "0    -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1    -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2    -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3    -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4    -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  0.023892  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120 -0.025803    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984 -0.031810    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  0.037789  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  0.045263  unstable  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = 'stab',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1     9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2     8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3     0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4     3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4     stabf  \n",
       "0    -1.723086  0.650456  0.859578  0.887445  0.958034  unstable  \n",
       "1    -1.255012  0.413441  0.862414  0.562139  0.781760    stable  \n",
       "2    -0.920492  0.163041  0.766689  0.839444  0.109853  unstable  \n",
       "3    -0.997374  0.446209  0.976744  0.929381  0.362718  unstable  \n",
       "4    -0.554305  0.797110  0.455450  0.656947  0.820923  unstable  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  unstable  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120    stable  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984    stable  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  unstable  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  unstable  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = LabelEncoder()\n",
    "#data['stabf'] = encoder.fit_transform(data['stabf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='stabf')\n",
    "y = data['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694    unstable\n",
       "5140    unstable\n",
       "2568    unstable\n",
       "3671    unstable\n",
       "7427    unstable\n",
       "          ...   \n",
       "2895      stable\n",
       "7813      stable\n",
       "905     unstable\n",
       "5192    unstable\n",
       "235       stable\n",
       "Name: stabf, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pred = log_reg.predict(x_test)\n",
    "log_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, log_pred)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 3)) #prints 53.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['stabf'] = encoder.fit_transform(data['stabf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 12)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "#y_train_scaled = scaler.fit_transform(y_train).reshape(-1, 1)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "x_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(random_state =1)\n",
    "log_reg.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "new_predictions = log_reg.predict(x_test_scaled)\n",
    "cnf_mat = confusion_matrix(y_test, new_predictions)\n",
    "cnf_mat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross-validation and accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(log_reg, x_train_scaled, y_train, cv=5, scoring='f1_macro')\n",
    "scores*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_pred = log_reg.predict(x_test_scaled)\n",
    "log_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = accuracy_score(y_test, log_pred)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state = 1)\n",
    "RFC.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_pred = RFC.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'stable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do for recall and f1 score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9191    0.8778    0.8980       712\n",
      "    unstable     0.9341    0.9573    0.9456      1288\n",
      "\n",
      "    accuracy                         0.9290      2000\n",
      "   macro avg     0.9266    0.9176    0.9218      2000\n",
      "weighted avg     0.9288    0.9290    0.9286      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, RFC_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, RFC_pred)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 3)) #prints 53.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra tree classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree = ExtraTreesClassifier()\n",
    "tree.fit(x_train_scaled, y_train)\n",
    "tree_pred = tree.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.94      0.86      0.90       712\n",
      "    unstable       0.92      0.97      0.95      1288\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.91      0.92      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, tree_pred)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 50, 100, 250, 400]\n",
    "min_samples_split = [2,3,5,7,9]\n",
    "min_samples_leaf = [1,2,4,6,8]\n",
    "max_features = ['auto', 'sprt', 'log2']\n",
    "#max_features = ['sqrt']\n",
    "hyperparameter_grid = {'n_estimators': n_estimators, 'min_samples_leaf': min_samples_split, 'max_features': max_features} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 255, in fit\n",
      "    raise ValueError(\"Invalid value for max_features. \"\n",
      "ValueError: Invalid value for max_features. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf = RandomizedSearchCV(tree,hyperparameter_grid, random_state = 1)\n",
    "search = clf.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_pred = clf.predict(x_test_scaled)\n",
    "tree_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([400, 2, 'log2'])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param = ExtraTreesClassifier(n_estimators = 400, min_samples_split = 2, min_samples_leaf = 1, max_features = 'log2')\n",
    "tree_param.fit(x_train_scaled, y_train)\n",
    "tree_param_pred = tree_param.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, tree_param_pred)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 4)) #prints 53.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable       0.97      0.84      0.90       712\n",
      "    unstable       0.92      0.99      0.95      1288\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.94      0.91      0.93      2000\n",
      "weighted avg       0.94      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_param_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11906170398692989"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tree_param.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_scaled = tree_param.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(X.columns, feature_importance_scaled)\n",
    "plt.xlabel('feature labels')\n",
    "plt.ylabel('feature importances')\n",
    "plt.title('comparism of different feature importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for xgboost using gradient boosting\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "extreme1 = XGBClassifier(max_depth = 3, learning_rate = 0.1)\n",
    "extreme1.fit(x_train_scaled, y_train)\n",
    "extreme1_pred = extreme1.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9206    0.8469    0.8822       712\n",
      "    unstable     0.9190    0.9596    0.9389      1288\n",
      "\n",
      "    accuracy                         0.9195      2000\n",
      "   macro avg     0.9198    0.9033    0.9105      2000\n",
      "weighted avg     0.9195    0.9195    0.9187      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, extreme1_pred,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, extreme1_pred)\n",
    "print('Accuracy: {}'.format(round(accuracy*100), 2)) #prints 53.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lightgbm) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from lightgbm) (1.16.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for lightgbm using LGBMClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "light = LGBMClassifier()\n",
    "light.fit(x_train_scaled, y_train)\n",
    "light_pred = light.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'stable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
